{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e40ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = \"hf_******yRkbHvj\"\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79315620",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Install a transformers version that supports Gemma 3n (>= 4.53)\n",
    "!pip install 'transformers>=4.53.0' 'timm>=1.0.16' -q\n",
    "\n",
    "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4326ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "GEMMA_PATH = 'google/gemma-3n-E4B-it'\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(GEMMA_PATH)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    GEMMA_PATH,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "print(f'Device: {model.device}')\n",
    "print(f'DType: {model.dtype}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63be1f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# def describe_audio(path: str, max_tokens: int = 64) -> str:\n",
    "#     \"\"\"Run Gemma-3n on a single audio file and return a short description.\"\"\"\n",
    "#     system_msg = {\n",
    "#         'role': 'system',\n",
    "#         'content': [\n",
    "#             {\n",
    "#                 'type': 'text',\n",
    "#                 'text': (\n",
    "#                     'You are an assistant that listens to a given background noise audio clip '\n",
    "#                     'and writes a short, high-level description of what is '\n",
    "#                     'happening in 1-2 sentences. Mainly describe the sound/noise - how is it and also do mention how loud/unpleasant it is. Based on these descriptions we will be using that audio as background noise when simulating a vapi voice assistant when calling an agent - so that it looks like a real background noise based on the assistants situation. So need the descriptions to select this particular background noise. Start \"Heading: \"Give a short heading for this background noise\"; Description: This noise..\"'\n",
    "#                 ),\n",
    "#             }\n",
    "#         ],\n",
    "#     }\n",
    "\n",
    "#     user_msg = {\n",
    "#         'role': 'user',\n",
    "#         'content': [\n",
    "#             {\n",
    "#                 'type': 'text',\n",
    "#                 'text': (\n",
    "#                     f\"Please describe the following audio file named \"\n",
    "#                     f\"'{os.path.basename(path)}' in 1-2 sentences.\"\n",
    "#                 ),\n",
    "#             },\n",
    "#             {\n",
    "#                 'type': 'audio',\n",
    "#                 'audio': path,\n",
    "#             },\n",
    "#         ],\n",
    "#     }\n",
    "\n",
    "#     messages = [system_msg, user_msg]\n",
    "\n",
    "#     input_ids = processor.apply_chat_template(\n",
    "#         messages,\n",
    "#         add_generation_prompt=True,\n",
    "#         tokenize=True,\n",
    "#         return_dict=True,\n",
    "#         return_tensors='pt',\n",
    "#     )\n",
    "#     input_len = input_ids['input_ids'].shape[-1]\n",
    "\n",
    "#     input_ids = input_ids.to(model.device, dtype=model.dtype)\n",
    "#     outputs = model.generate(\n",
    "#         **input_ids,\n",
    "#         max_new_tokens=max_tokens,\n",
    "#         disable_compile=True,\n",
    "#     )\n",
    "\n",
    "#     decoded = processor.batch_decode(\n",
    "#         outputs[:, input_len:],\n",
    "#         skip_special_tokens=True,\n",
    "#         clean_up_tokenization_spaces=True,\n",
    "#     )\n",
    "#     return decoded[0].strip()\n",
    "\n",
    "\n",
    "def describe_audio(path: str, max_tokens: int = 256) -> str:\n",
    "    \"\"\"Run Gemma-3n on a single audio file and return a JSON description object as a string.\"\"\"\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"You are an assistant that listens to a background noise audio clip and \"\n",
    "                    \"outputs a single JSON object describing it for use as call background.\\n\\n\"\n",
    "                    \"Your ONLY output must be a valid JSON object, with no extra text, in this exact shape: {...}\\n\\n\"\n",
    "                    \"- Do NOT wrap the JSON in ``` or any code fences.\\n\"\n",
    "                    \"- Do NOT prefix it with 'json' or any language label.\\n\"\n",
    "                    \"- Do NOT write anything before or after the JSON object.\\n\"\n",
    "                    \"{\\n\"\n",
    "                    '  \"id\": \"short_snake_case_identifier\",\\n'\n",
    "                    '  \"path\": \"<<<COPY THE EXACT path STRING PROVIDED>>>\",\\n'\n",
    "                    '  \"name\": \"Short human-readable name\",\\n'\n",
    "                    '  \"environment\": \"one of: office, home, outdoors, transit, retail, vehicle, neutral\",\\n'\n",
    "                    '  \"noise_level\": \"one of: low, medium, high\",\\n'\n",
    "                    '  \"energy\": \"one of: calm, neutral, busy, chaotic\",\\n'\n",
    "                    '  \"pleasantness\": \"one of: pleasant, neutral, unpleasant\",\\n'\n",
    "                    '  \"voices_intelligible\": true or false,\\n'\n",
    "                    '  \"context_examples\": [\\n'\n",
    "                    '    \"one example of a caller situation where this background fits\",\\n'\n",
    "                    '    \"optionally a second short example\"\\n'\n",
    "                    \"  ],\\n\"\n",
    "                    '  \"notes\": \"1–2 sentences summarizing what the noise sounds like and how loud/unpleasant it is\"\\n'\n",
    "                    \"}\\n\\n\"\n",
    "                    \"- Use the audio to set noise_level, energy and pleasantness.\\n\"\n",
    "                    \"- Use generic, reusable context examples (e.g., “caller in a busy office” or “caller walking through a mall”).\\n\"\n",
    "                    \"- Always copy the path string exactly from the user message into the `path` field.\\n\"\n",
    "                    \"- Do NOT include any commentary or text outside the JSON object. Also don't include any code blocks like: '```json' in your response.. just the json object that I can parse it directly using python's parser.\"\n",
    "                ),\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"Given this audio file, produce the JSON object as described in the system message. \"\n",
    "                    f\"The file path is: {path}\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"audio\",\n",
    "                \"audio\": path,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    messages = [system_msg, user_msg]\n",
    "\n",
    "    input_ids = processor.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_len = input_ids[\"input_ids\"].shape[-1]\n",
    "\n",
    "    input_ids = input_ids.to(model.device, dtype=model.dtype)\n",
    "    outputs = model.generate(\n",
    "        **input_ids,\n",
    "        max_new_tokens=max_tokens,\n",
    "        disable_compile=True,\n",
    "    )\n",
    "\n",
    "    decoded = processor.batch_decode(\n",
    "        outputs[:, input_len:],\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True,\n",
    "    )\n",
    "    return decoded[0].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d9161",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from glob import glob\n",
    "\n",
    "# def describe_audio_directory(directory: str, patterns=None, json_filename=\"audio_descriptions.json\"):\n",
    "#     \"\"\"Find all audio files in a directory, describe them, and save to JSON.\"\"\"\n",
    "#     if patterns is None:\n",
    "#         patterns = ('*.wav', '*.mp3', '*.flac', '*.ogg', '*.m4a')\n",
    "\n",
    "#     paths = []\n",
    "#     for pattern in patterns:\n",
    "#         paths.extend(glob(os.path.join(directory, pattern)))\n",
    "\n",
    "#     paths = sorted(set(paths))\n",
    "#     if not paths:\n",
    "#         print(f'No audio files found in {directory}')\n",
    "#         return []\n",
    "\n",
    "#     results = []\n",
    "#     for path in paths:\n",
    "#         print(f\"\\n=== {os.path.basename(path)} ===\")\n",
    "#         try:\n",
    "#             description = describe_audio(path)\n",
    "#         except Exception as e:\n",
    "#             print(f'Error describing {path}: {e}')\n",
    "#             continue\n",
    "#         print(description)\n",
    "#         results.append({\n",
    "#             \"path\": path,\n",
    "#             \"description\": description,\n",
    "#         })\n",
    "\n",
    "#     # Save results as JSON\n",
    "#     json_path = os.path.join(directory, json_filename)\n",
    "#     with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "#     print(f\"\\nSaved {len(results)} descriptions to {json_path}\")\n",
    "#     return results\n",
    "\n",
    "import json\n",
    "\n",
    "def describe_audio_directory(directory: str, patterns=None, json_filename=\"audio_descriptions.json\"):\n",
    "    \"\"\"Find all audio files in a directory, describe them, and save normalized JSON objects.\"\"\"\n",
    "    if patterns is None:\n",
    "        patterns = (\"*.wav\", \"*.mp3\", \"*.flac\", \"*.ogg\", \"*.m4a\")\n",
    "\n",
    "    paths = []\n",
    "    for pattern in patterns:\n",
    "        paths.extend(glob(os.path.join(directory, pattern)))\n",
    "\n",
    "    paths = sorted(set(paths))\n",
    "    if not paths:\n",
    "        print(f\"No audio files found in {directory}\")\n",
    "        return []\n",
    "\n",
    "    results = []\n",
    "    for path in paths:\n",
    "        print(f\"\\n=== {os.path.basename(path)} ===\")\n",
    "        try:\n",
    "            raw = describe_audio(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error describing {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(\"Model raw output:\")\n",
    "        print(raw)\n",
    "        try:\n",
    "            obj = json.loads(raw)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON for {path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure path is correct, even if the model messed it up\n",
    "        obj[\"path\"] = path\n",
    "\n",
    "        results.append(obj)\n",
    "\n",
    "    # Save results as JSON\n",
    "    json_path = os.path.join(directory, json_filename)\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nSaved {len(results)} descriptions to {json_path}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d38b35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Change this to another path if needed\n",
    "audio_dir = '/content/bg_noises'\n",
    "\n",
    "results = describe_audio_directory(audio_dir)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4b585",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44ed33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/KarthikAvinashFI/bg_noises.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b83be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cd bg_noises/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
